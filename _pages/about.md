---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# ğŸ¤“ About Me

My name is Guanzhou Chen (é™ˆå† å· in Chinese), and I am a first-year Ph.D. student in the School of Electronic Information and Electrical Engineering at Shanghai Jiao Tong University, supervised by [Prof. Jifeng Dai](https://jifengdai.org/) and [Prof. Yu Qiao](https://scholar.google.com/citations?user=gFtI-8QAAAAJ). Before this, I obtained my bachelor's degree in the School of Computer Science at Beijing University of Posts and Telecommunications in 2024.

I am also a trainee researcher at the Shanghai AI Lab. Prior to that, I was fortunate to be a research intern at **BIGAI** (Beijing Institute for General Artificial Intelligence), under the supervision of [Prof. Yitao Liang](https://web.cs.ucla.edu/~yliang/).

# ğŸ”¬ Research Interests

I work on vision-language models and am interested in related topics, including decision-making and large pre-trained foundation models.

# ğŸ”¥ News

- *2025/05*: &nbsp;ğŸ‰ğŸ‰ [VeBrain](https://internvl.github.io/blog/2025-05-26-VeBrain/) is released, demonstrating the first framework unifying multimodal understanding, spatial intelligence and robot control!
- *2025/02*: &nbsp;ğŸ‰ğŸ‰ [OmniCorpus](https://arxiv.org/pdf/2406.08418) is accepted by ICLR2025 as Spotlight!
- *2024/12*: &nbsp;ğŸ‰ğŸ‰ Our team released [InternVL-2.5](https://internvl.github.io/blog/2024-12-05-InternVL-2.5/)!
- *2023/10*: &nbsp;ğŸ‰ğŸ‰ I received CCF Elite Collegiate Award (top 99 nationwide)!

# ğŸ“ Publications 
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv</div><img src='images/papers/2506.00123.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Visual Embodied Brain: Let Multimodal Large Language Models See, Think, and Control in Spaces](https://internvl.github.io/blog/2025-05-26-VeBrain/)

Gen Luo\*, Ganlin Yang\*, Ziyang Gong\*, **Guanzhou Chen**\*, Haonan Duan, Erfei Cui, Ronglei Tong, Zhi Hou, Tianyi Zhang, Zhe Chen, Shenglong Ye, Lewei Lu, Jingbo Wang, Wenhai Wang, Jifeng Dai, Yu Qiao, Rongrong Ji, Xizhou Zhu

Arxiv | [Homepage](https://internvl.github.io/blog/2025-05-26-VeBrain/) | [Paper](https://arxiv.org/pdf/2506.00123) | [Model](https://huggingface.co/OpenGVLab/VeBrain) | [Code](https://github.com/OpenGVLab/VeBrain) | ![Stars](https://img.shields.io/github/stars/OpenGVLab/VeBrain)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR2025</div><img src='images/papers/2406.08418.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[OmniCorpus: A Unified Multimodal Corpus of 10 Billion-Level Images Interleaved with Text](https://arxiv.org/pdf/2406.08418)

<!--
Qingyun Li, Zhe Chen, Weiyun Wang, Wenhai Wang, Shenglong Ye, Zhenjiang Jin, **Guanzhou Chen**, Yinan He, Zhangwei Gao, Erfei Cui, Jiashuo Yu, Hao Tian, Jiasheng Zhou, Chao Xu, Bin Wang, Xingjian Wei, Wei Li, Wenjian Zhang, Bo Zhang, Pinlong Cai, Licheng Wen, Xiangchao Yan, Zhenxiang Li, Pei Chu, Yi Wang, Min Dou, Changyao Tian, Xizhou Zhu, Lewei Lu, Yushi Chen, Junjun He, Zhongying Tu, Tong Lu, Yali Wang, Limin Wang, Dahua Lin, Yu Qiao, Botian Shi, Conghui He, Jifeng Dai
-->

Qingyun Li, Zhe Chen, Weiyun Wang, Wenhai Wang, Shenglong Ye, Zhenjiang Jin, **Guanzhou Chen**, Yinan He, Zhangwei Gao, Erfei Cui, Jiashuo Yu, Hao Tian, Jiasheng Zhou, Chao Xu, Bin Wang, Xingjian Wei, Wei Li, Wenjian Zhang, Bo Zhang, Pinlong Cai, Licheng Wen, Xiangchao Yan, Zhenxiang Li, Pei Chu, Yi Wang, ..., Limin Wang, Dahua Lin, Yu Qiao, Botian Shi, Conghui He, Jifeng Dai

**ICLR 2025 (Spotlight)** | [Paper](https://arxiv.org/pdf/2406.08418) | [Code](https://github.com/OpenGVLab/OmniCorpus) | ![Stars](https://img.shields.io/github/stars/OpenGVLab/OmniCorpus)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='images/papers/2302.01560.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents](https://arxiv.org/pdf/2302.01560.pdf)

<font color="red">Best Paper Award, ICML 2023 TEACH Workshop</font>

Zihao Wang, Shaofei Cai, **Guanzhou Chen**, Anji Liu, Xiaojian Ma, Yitao Liang

**NeurIPS 2023** | [Paper](https://arxiv.org/pdf/2302.01560.pdf) | [Code](https://github.com/CraftJarvis/MC-Planner) | ![Stars](https://img.shields.io/github/stars/CraftJarvis/MC-Planner)
</div>
</div>

# ğŸŒŸ Selected Honors and Awards

- *2023/10* CCF Elite Collegiate Award **(top 99 nationwide)**
- *2023/07* Best Paper Award, ICML 2023 TEACH Workshop
- *2022/07* Silver Medal, ICPC Asia-East Final
- *2021/11* Gold Medal, 9th place, 2021 China Collegiate Programming Contest, Harbin ğŸ…
- *2021/11* Gold Medal, 20th place, 46th ICPC Asia, Shenyang ğŸ…
- *2021/04* Gold Medal, 13th place, 45th ICPC Asia, Kunming ğŸ…
- *2019/07* Brozen Medal, 36th National Olympic in Informatics

# ğŸ“– Educations
<div class='school-box'>
<div><img src='images/sjtu.jpg' alt="sym" width="80"></div>
<div class='school-box-text' markdown="1">
2024/09 - now, Ph.D. student

School of Electronic Information and Electrical Engineering

Shanghai Jiao Tong University, Shanghai
</div>
</div>

<div class='school-box'>
<div><img src='images/bupt.png' alt="sym" width="80"></div>
<div class='school-box-text' markdown="1">
2020/09 - 2024/06, Bachelor

School of Computer Science

Beijing University of Posts and Telecommunications, Beijing
</div>
</div>



<!--
# ğŸ’¬ Invited Talks
- *2021/06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021/03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)
-->

# ğŸ’» Internships

- *2024/02 - Now*: Trainee researcher at [Shanghai Artificial Intelligence Laboratory](https://www.shlab.org.cn/), Beijing/Shanghai.
- *2023/02 - 2023/07*: Research intern at [BIGAI](https://www.bigai.ai/), Beijing.
